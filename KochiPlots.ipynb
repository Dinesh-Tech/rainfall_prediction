{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/saugatbh/RainfallDataAnalysis/blob/main/BhubhaneshwarPlots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7fXpRWj_fy2h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Bidirectional,GRU\n",
    "from keras.layers import Flatten, Dropout,Reshape\n",
    "from keras import callbacks\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hQn6h6mDEuCg"
   },
   "outputs": [],
   "source": [
    "def compareall(ytest,yhat,mname):\n",
    "  plt.figure(figsize = (12, 5))\n",
    "  p1=plt.figure(1)\n",
    "  plt.plot(ytest, label='True',marker='o')\n",
    "  plt.plot(yhat,  label='Predicted',marker='+')\n",
    "  plt.legend()\n",
    "  plt.title('Predicted vs True Values using '+mname)\n",
    "  plt.xlabel('time(month)')\n",
    "  plt.ylabel('normalized value')\n",
    "  p2=plt.figure(2)\n",
    "  plt.figure(figsize = (12, 5))\n",
    "  plt.plot(yhat-ytest,label = 'Difference',marker = '*')\n",
    "  plt.legend()\n",
    "  plt.title('Difference in True and Predicted Values')\n",
    "  plt.xlabel('time(month)')\n",
    "  plt.ylabel('normalized value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0ic9MCtnMzJi"
   },
   "outputs": [],
   "source": [
    "def plot_loss (history, model_name):\n",
    "    #plt.figure(figsize = (10, 6))\n",
    "    p1=plt.figure(1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Train Loss for ' + model_name)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train loss','Val Loss'], loc='upper right')\n",
    "    \n",
    "    p2=plt.figure(2)\n",
    "    plt.plot(history.history['mean_absolute_error'])\n",
    "    plt.title('Model MAE for ' + model_name)\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['MAE'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "02StdomYRphn"
   },
   "outputs": [],
   "source": [
    "def chopping(data):\n",
    "  n=data.shape[0]\n",
    "  train = data[0:int(n*0.87)]\n",
    "  ##val = data[int(n*0.7):int(n*0.9)]\n",
    "  test = data[int(n*0.87):]\n",
    "  return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HfaIQAoOmFJk"
   },
   "outputs": [],
   "source": [
    "def create_dataset (X, look_back = 1):\n",
    "  Xs, ys = [], []\n",
    "  for i in range(len(X)-look_back):\n",
    "    v = X[i:i+look_back]\n",
    "    Xs.append(v)\n",
    "    ys.append(X[i+look_back])\n",
    "  return np.array(Xs), np.array(ys)\n",
    "\n",
    "def compile_fit(model):\n",
    "  model.compile(loss='mean_squared_error',optimizer='adam',metrics='mean_absolute_error')\n",
    "  early_stop = callbacks.EarlyStopping(monitor = 'mean_absolute_error',patience = 10,mode='min')\n",
    "  history = model.fit(Xtrain, ytrain, epochs = 100,verbose=0,validation_split = 0.2,batch_size = 32, shuffle = False,callbacks = [early_stop])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXGbPzUf6wv9"
   },
   "source": [
    "**Reading and splitting data for Bhubhaneshwar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8U0uikOgz9A",
    "outputId": "c1b7cafe-9f64-4435-83eb-3fde582cd15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sape of data: (115, 12, 129, 135)\n",
      "Shape of selected place data: (115, 12, 3, 3)\n",
      "After reshaping: (1380, 9)\n",
      "Shape of input(x): (1344, 36, 9)\n",
      "shape of label(y): (1344, 9)\n",
      "X_train.shape:  (1169, 36, 9)\n",
      "y_train.shape:  (1169, 9)\n",
      "X_test.shape:  (175, 36, 9)\n",
      "y_test.shape:  (175, 9)\n"
     ]
    }
   ],
   "source": [
    "performance={}\n",
    "rmse={}\n",
    "years = np.arange(1901, 2015)\n",
    "months = ['Jan', 'Feb', 'March', 'April', 'May', 'June', 'July', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n",
    "data = np.load('rainfall_data.npy')\n",
    "data = np.where(data<0,0,data)\n",
    "print('Original sape of data:',data.shape)\n",
    "one_grid = data[:,:,79,56]\n",
    "one_grid=one_grid.reshape([one_grid.shape[0] * one_grid.shape[1], 1])\n",
    "one_grid = preprocessing.normalize(one_grid)\n",
    "\n",
    "region = data[:, :,78:81, 55:58]\n",
    "print('Shape of selected place data:',region.shape)\n",
    "region = region.reshape([region.shape[0] * region.shape[1], 9])\n",
    "region=preprocessing.normalize(region)\n",
    "print('After reshaping:',region.shape)\n",
    "x,y=create_dataset(region,36)\n",
    "print('Shape of input(x):',x.shape)\n",
    "print('shape of label(y):',y.shape)\n",
    "Xtrain,Xtest=chopping(x)\n",
    "ytrain,ytest=chopping(y)\n",
    "print('X_train.shape: ', Xtrain.shape)\n",
    "print('y_train.shape: ', ytrain.shape)\n",
    "print('X_test.shape: ', Xtest.shape) \n",
    "print('y_test.shape: ', ytest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrpRjP3lCQah"
   },
   "source": [
    "**Defining models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "y-mqv0r8WRam"
   },
   "outputs": [],
   "source": [
    "def lstm_model(unit):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(units=unit,input_shape=(Xtrain.shape[1],Xtrain.shape[2]),return_sequences=True))\n",
    "  model.add(LSTM(units=unit))\n",
    "  model.add(Dense(1))\n",
    "  return model\n",
    "\n",
    "def bilstm_model(unit):\n",
    "  model=Sequential()\n",
    "  model.add(Bidirectional(LSTM(units = unit, return_sequences=True),input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "  model.add(Bidirectional(LSTM(units = unit)))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(1))\n",
    "  return model\n",
    "\n",
    "def gru_model(unit):\n",
    "  model=Sequential()\n",
    "  model.add(GRU (units = unit, return_sequences = True,input_shape = [x.shape[1], x.shape[2]]))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(GRU(units = unit))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(units = 1))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqCOvEKP9gNl"
   },
   "source": [
    "**Prediction using test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YTrRGnXk4Ljz",
    "outputId": "eafdd4e8-1052-4fdd-b63f-6a31a9ed6910"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Type of `metrics` argument not understood. Expected a list or dictionary, found: mean_absolute_error",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-22f30b5406cd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mm2\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbilstm_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mm3\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgru_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mh1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompile_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mh2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompile_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mh3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompile_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-5-16a47a88bd12>\u001B[0m in \u001B[0;36mcompile_fit\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mcompile_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m   \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'mean_squared_error'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'adam'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'mean_absolute_error'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m   \u001B[0mearly_stop\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'mean_absolute_error'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mpatience\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'min'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m   \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mXtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mytrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalidation_split\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0.2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m32\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshuffle\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mearly_stop\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nanma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001B[0m in \u001B[0;36msymbolic_fn_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     73\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_SYMBOLIC_SCOPE\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mget_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_default\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nanma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mcompile\u001B[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m         \u001B[1;31m# Save all metric attributes per output of the model.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_cache_output_metric_attributes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweighted_metrics\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    212\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m         \u001B[1;31m# Set metric attributes on model.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nanma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_cache_output_metric_attributes\u001B[1;34m(self, metrics, weighted_metrics)\u001B[0m\n\u001B[0;32m    736\u001B[0m                 \u001B[0moutput_shapes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    737\u001B[0m         self._per_output_metrics = training_utils.collect_per_output_metric_info(\n\u001B[1;32m--> 738\u001B[1;33m             metrics, self.output_names, output_shapes, self.loss_functions)\n\u001B[0m\u001B[0;32m    739\u001B[0m         self._per_output_weighted_metrics = (\n\u001B[0;32m    740\u001B[0m             training_utils.collect_per_output_metric_info(\n",
      "\u001B[1;32mc:\\users\\nanma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_utils.py\u001B[0m in \u001B[0;36mcollect_per_output_metric_info\u001B[1;34m(metrics, output_names, output_shapes, loss_fns, is_weighted)\u001B[0m\n\u001B[0;32m    933\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m         raise TypeError('Type of `metrics` argument not understood. '\n\u001B[1;32m--> 935\u001B[1;33m                         'Expected a list or dictionary, found: ' + str(metrics))\n\u001B[0m\u001B[0;32m    936\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    937\u001B[0m     \u001B[0mper_output_metrics\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Type of `metrics` argument not understood. Expected a list or dictionary, found: mean_absolute_error"
     ]
    }
   ],
   "source": [
    "m1=lstm_model(64)\n",
    "m2=bilstm_model(64)\n",
    "m3=gru_model(64)\n",
    "h1 = compile_fit(m1)\n",
    "h2 = compile_fit(m2)\n",
    "h3 = compile_fit(m3)\n",
    "performance['lstm']=m1.evaluate(Xtest)\n",
    "performance['bilstm']=m2.evaluate(Xtest)\n",
    "performance['gru']=m3.evaluate(Xtest)\n",
    "print(\"fitting done\")\n",
    "yhat1 = m1.predict(Xtest)\n",
    "yhat2 = m2.predict(Xtest)\n",
    "yhat3 = m3.predict(Xtest)\n",
    "print(\"Prediction shape=\",yhat1.shape,yhat2.shape,yhat3.shape)\n",
    "print(\"predict done\")\n",
    "Score_lstm = sqrt(mean_squared_error(ytest[:,4],yhat1[:,0]))\n",
    "Score_bilstm = sqrt(mean_squared_error(ytest[:,4],yhat2[:,0]))\n",
    "Score_gru = sqrt(mean_squared_error(ytest[:,4],yhat3[:,0]))\n",
    "print(\"RMSE(LSTM)= \",Score_lstm)\n",
    "print(\"RMSE(BiLSTM)= \",Score_bilstm)\n",
    "print(\"RMSE(GRU)= \",Score_gru)\n",
    "rmse['lstm']=Score_lstm\n",
    "rmse['bilstm']=Score_bilstm\n",
    "rmse['gru']=Score_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "eVmGOpdXMwM3",
    "outputId": "709bc0b8-5f6b-410e-8399-73c908235838"
   },
   "outputs": [],
   "source": [
    "plot_loss(h1,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Z_OFNQg6Mznx",
    "outputId": "5104840d-6839-40aa-f112-7499dcc9b6df"
   },
   "outputs": [],
   "source": [
    "plot_loss(h2,'BiLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7JtTrf55M3AU",
    "outputId": "03473255-6bc8-452f-de10-b0b9647cd1c9"
   },
   "outputs": [],
   "source": [
    "plot_loss(h3,'GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0G_gm60Jm9Lb",
    "outputId": "fb23d05f-73d2-4517-a374-65cc95e8ca53"
   },
   "outputs": [],
   "source": [
    "yhat1_mean=(np.mean(yhat1,axis=1))\n",
    "yhat2_mean=(np.mean(yhat2,axis=1))\n",
    "yhat3_mean=(np.mean(yhat3,axis=1))\n",
    "ytest_mean=(np.mean(ytest,axis=1))\n",
    "print(\"RMSE(LSTM)= \",sqrt(mean_squared_error(ytest_mean,yhat1_mean)))\n",
    "print(\"RMSE(BiLSTM)= \",sqrt(mean_squared_error(ytest_mean,yhat2_mean)))\n",
    "print(\"RMSE(GRU)= \",sqrt(mean_squared_error(ytest_mean,yhat3_mean)))\n",
    "\n",
    "compareall(ytest_mean,yhat1_mean,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1om5EHRePSM0",
    "outputId": "7d9dae49-7971-4316-8bc5-107b97795552"
   },
   "outputs": [],
   "source": [
    "compareall(ytest_mean,yhat2_mean,'BiLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "q_yXUoaEPRU_",
    "outputId": "6f5b0e88-8d70-45a9-9c0a-b80a9f3b705a"
   },
   "outputs": [],
   "source": [
    "compareall(ytest_mean,yhat3_mean,'GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj9eA2Kr3JDJ"
   },
   "source": [
    "**Prediction for last 15 years**\n",
    "\n",
    "starts from 1164th of total no of windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_y7WdsYzzunW",
    "outputId": "461a2a35-e163-4ffe-9b4f-2d826b5cf437"
   },
   "outputs": [],
   "source": [
    "lstm_pred_15year=m1.predict(x[1164:,:,:])\n",
    "bilstm_pred_15year=m2.predict(x[1164:,:,:])\n",
    "gru_pred_15year=m3.predict(x[1164:,:,:])\n",
    "newy=(y[1164:,4:5])\n",
    "yhat1_mean=(np.mean(lstm_pred_15year,axis=1))\n",
    "yhat2_mean=(np.mean(bilstm_pred_15year,axis=1))\n",
    "yhat3_mean=(np.mean(gru_pred_15year,axis=1))\n",
    "ytest_mean=(np.mean(newy,axis=1))\n",
    "print('RMSE(lstm):',sqrt(mean_squared_error(newy,lstm_pred_15year)))\n",
    "print('RMSE(bilstm):',sqrt(mean_squared_error(newy,bilstm_pred_15year)))\n",
    "print('RMSE(gru):',sqrt(mean_squared_error(newy,gru_pred_15year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "qKkUQ80FQDw_",
    "outputId": "0a618e55-8812-42fd-9a82-955e1773ed94"
   },
   "outputs": [],
   "source": [
    "compareall(ytest_mean,yhat1_mean,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LLz7Z3uxQDSM",
    "outputId": "15e3bef1-ea4b-498d-ca1f-c51547f3873a"
   },
   "outputs": [],
   "source": [
    "compareall(ytest_mean,yhat2_mean,'BiLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "pdzdgt7SQDCp",
    "outputId": "85950f4d-f01b-4edb-f136-473548447db5"
   },
   "outputs": [],
   "source": [
    "compareall(ytest_mean,yhat3_mean,'GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CkdGxLVFUcKH",
    "outputId": "8e5bfa57-0f0b-469d-f732-ee44f2dd07d0"
   },
   "outputs": [],
   "source": [
    "for i in range(len(months)):\n",
    "  actual=newy[i:180:12]\n",
    "  lstm_pred=lstm_pred_15year[i:180:12]\n",
    "  bilstm_pred=bilstm_pred_15year[i:180:12]\n",
    "  gru_pred=gru_pred_15year[i:180:12]\n",
    "  p1=plt.figure(i)\n",
    "  plt.plot(np.arange(2001,2016),lstm_pred,label='LSTM Prediction',marker='.')\n",
    "  plt.plot(np.arange(2001,2016),bilstm_pred,label='BiLSTM Prediction',marker='.')\n",
    "  plt.plot(np.arange(2001,2016),gru_pred,label='GRU Prediction',marker='.')\n",
    "  plt.plot(np.arange(2001,2016),actual,label='True value',marker='.')\n",
    "  plt.title('Results for ' + months[i])\n",
    "  plt.ylabel('Rainfall (normalized)')\n",
    "  plt.xlabel('Years')\n",
    "  plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jrN-5k6Lpo1H",
    "outputId": "e570ee4d-4fa9-4078-fbd8-896fa1804fe4"
   },
   "outputs": [],
   "source": [
    "lstm_pred_15year=lstm_pred_15year.reshape(12,15)\n",
    "bilstm_pred_15year=bilstm_pred_15year.reshape(12,15)\n",
    "gru_pred_15year=gru_pred_15year.reshape(12,15)\n",
    "newy=newy.reshape(12,15)\n",
    "for i in range(12):\n",
    "  p1=plt.figure(i)\n",
    "  plt.figure(figsize = (7, 5))\n",
    "  plt.plot(np.arange(2001,2016),abs(lstm_pred_15year[i]-newy[i]),marker='.',label='LSTM')\n",
    "  plt.plot(np.arange(2001,2016),abs(bilstm_pred_15year[i]-newy[i]),marker='.',label='BiLSTM')\n",
    "  plt.plot(np.arange(2001,2016),abs(gru_pred_15year[i]-newy[i]),marker='.',label='GRU')\n",
    "  plt.title('Absolute Error for ' + months[i])\n",
    "  plt.ylabel('Error (normalized)')\n",
    "  plt.xlabel('Years')\n",
    "  plt.legend(loc='upper right')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPmF1BoR6SoUkkj4h4S7eKr",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1cWr3e6Tz7MhZcUo5BcSUKbuIMC_hNNWA",
   "name": "BhubhaneshwarPlots.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}